# -*- coding: utf-8 -*-
"""
Created on Fri May 28 10:18:25 2021

@author: 10641168
"""

import numpy as np
import pandas as pd
import seaborn as  sns
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn import preprocessing
from collections import Counter
from sklearn.metrics import classification_report,accuracy_score
dataset=pd.read_csv("winequality-red.csv")
dataset.head() 
print(dataset.shape)
features_with_na=[features for features in dataset.columns if dataset[features].isnull().sum()>1]
for feature in features_with_na:
    print(feature, np.round(dataset[feature].isnull().mean(), 4),  ' % missing values')
    
    # list of numerical variables
numerical_features = [feature for feature in dataset.columns if dataset[feature].dtypes != 'O']

print('Number of numerical variables: ', len(numerical_features))
dataset[numerical_features].head()
bins = (2, 6.5, 8)
group_names = ['bad', 'good']
dataset['quality'] = pd.cut(dataset['quality'], bins = bins, labels = group_names)
print (dataset['quality'] )
#Label encoding as the quality parameter is categorised as good/bad
label_encoder=preprocessing.LabelEncoder()
dataset['quality']=label_encoder.fit_transform(dataset['quality'])
print(dataset.head())
sns.pairplot(dataset)
plt.show()
ax = sns.violinplot(x=dataset['quality'])
ax_violin = sns.violinplot(x="fixed acidity", y="quality", data=dataset)
#Create independent and Dependent Features
columns = dataset.columns.tolist()
# Filter the columns to remove data we do not want 
columns = [c for c in columns if c not in ["quality"]]
# Store the variable we are predicting 
target = "quality"
# Define a random state 
state = np.random.RandomState(42)
X = dataset[columns]
Y = dataset[target]
sns.set_style('whitegrid')
plt.figure(figsize=(12, 6))
sns.countplot(x="quality", data=dataset, palette='husl');


#### OUTLIER DETECTION

def detect_outliers(columns):
    outlier_indices = []

    for column in columns:
        # 1st quartile
        Q1 = np.percentile(dataset[column], 25)
        # 3st quartile
        Q3 = np.percentile(dataset[column], 75)
        # IQR
        IQR = Q3 - Q1
        # Outlier Step
        outlier_step = IQR * 1.5
        # detect outlier and their indeces
        outlier_list_col = dataset[(dataset[column] < Q1 - outlier_step)
                              | (dataset[column] > Q3 + outlier_step)].index
        # store indeces
        outlier_indices.extend(outlier_list_col)

    outlier_indices = Counter(outlier_indices)
    multiple_outliers = list(i for i, v in outlier_indices.items() if v > 1.5)

    return multiple_outliers

dataset.loc[detect_outliers(dataset.columns[:-1])]
print("number of outliers detected --> ",
      len(dataset.loc[detect_outliers(dataset.columns[:-1])]))
dataset = dataset.drop(detect_outliers(dataset.columns[:-1]),axis = 0).reset_index(drop = True)

#Handling imbalanced datatset
from imblearn.combine import SMOTETomek
# Implementing Oversampling for Handling Imbalanced 
smk = SMOTETomek(random_state=42)
X_res,y_res=smk.fit_sample(X,Y)
from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test=train_test_split(X_res,y_res,train_size=0.7)

#standard scaling
from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)
from sklearn.ensemble import RandomForestClassifier
classifier=RandomForestClassifier()
classifier.fit(X_train,y_train)
y_pred=classifier.predict(X_test)
print("forecasted",y_pred)
print("Jesus")
print( accuracy_score(y_test,y_pred))
print(classification_report(y_test,y_pred))


import pickle
# open a file, where you ant to store the data
file = open('random_forest_classifier_model.pkl', 'wb')

# dump information to that file
pickle.dump(classifier, file)


